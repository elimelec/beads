{"id":"bd-1","title":"Write tests for merge functionality","description":"Unit tests: validation, merge logic, data integrity. Integration tests: end-to-end workflow, export/import. Edge case tests: chains, circular refs, epics.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.627941-07:00"}
{"id":"bd-10","title":"Consider implementing pre-commit hooks for Storage interface changes","description":"The documentation (INTERFACE_CHANGES.md) suggests adding pre-commit hooks that automatically check for Storage interface changes and verify all mocks are updated. This would prevent similar issues in the future where interface changes break mock implementations.\n\nDiscovered during execution of vc-228 (dogfooding run #14/15).","design":"Implement a pre-commit hook that:\n1. Detects changes to internal/storage/storage.go\n2. Runs scripts/find-storage-mocks.sh to find all mock implementations\n3. Attempts to compile all test files with mocks\n4. Blocks commit if compilation fails\n\nTools: husky, pre-commit framework, or simple .git/hooks/pre-commit script","acceptance_criteria":"- Pre-commit hook installed and documented\n- Hook detects Storage interface changes\n- Hook validates all mocks compile\n- Hook can be bypassed with --no-verify if needed\n- Documentation updated with installation instructions","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.628547-07:00"}
{"id":"bd-11","title":"Add transaction support for atomic merges","description":"Wrap all merge operations in SQLite transaction for atomicity. Implement rollback on failure.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.629048-07:00"}
{"id":"bd-12","title":"Update export/import for merge fields","description":"Include merged_into in JSONL export format. Handle merge relationships on import.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.629379-07:00"}
{"id":"bd-13","title":"Add compact --dry-run that shows size savings estimates","description":"When running 'bd compact --dry-run', show estimated database size reduction in KB/MB and percentage, similar to what 'du -h' would show.\n\nExample output:\n  Tier 1 candidates: 15 issues\n  Current size: 2.4 MB\n  After compaction: ~1.7 MB (70% reduction, 0.7 MB saved)\n  \nThis helps users understand impact before compacting.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.629655-07:00"}
{"id":"bd-14","title":"Add rule-based compaction (e.g., compact children of closed epics)","description":"Support semantic compaction rules beyond just time-based, such as:\n- Compact all children of closed epics\n- Compact by priority level (e.g., all P3/P4 closed issues)\n- Compact by label (e.g., all issues labeled 'archive')\n- Compact by type (e.g., all closed chores)\n\nThis would allow smarter database size management based on semantic meaning rather than just age.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.629988-07:00"}
{"id":"bd-15","title":"Make merge command idempotent for safe retry after partial failures","description":"The merge command currently performs 3 operations without an outer transaction:\n1. Migrate dependencies from source → target\n2. Update text references across all issues\n3. Close source issues\n\nIf merge fails mid-operation (network issue, daemon crash, etc.), a retry will fail or produce incorrect results because some operations already succeeded.\n\n**Goal:** Make merge idempotent so retrying after partial failure is safe and completes the remaining work.\n\n**Idempotency checks needed:**\n- Skip dependency migration if target already has the dependency\n- Skip text reference updates if already updated\n- Skip closing source issues if already closed\n- Report which operations were skipped vs performed\n\n**Example output:**\n```\n✓ Merged 2 issue(s) into bd-128\n  - Dependencies: 3 migrated, 2 already existed\n  - Text references: 5 updated, 0 already correct\n  - Source issues: 1 closed, 1 already closed\n```\n\n**Related:** bd-53 originally requested transaction support, but idempotency is a better solution for this use case since individual operations are already atomic.","design":"Current merge code already has some idempotency:\n- Dependency migration checks `alreadyExists` before adding (line ~145-151 in merge.go)\n- Text reference updates are naturally idempotent (replacing bd-X with bd-Y twice has same result)\n\nMissing idempotency:\n- CloseIssue fails if source already closed\n- Error messages don't distinguish \"already done\" from \"real failure\"\n\nImplementation:\n1. Check source issue status before closing - skip if already closed\n2. Track which operations succeeded/skipped\n3. Return detailed results for user visibility\n4. Consider adding --dry-run output showing what would be done vs skipped","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.630298-07:00"}
{"id":"bd-16","title":"Add --id flag to bd list for filtering by specific issue IDs","description":"","design":"Add --id flag accepting comma-separated IDs. Usage: bd list --id wy-11,wy-12. Combines with other filters. From filter-flag-design.md.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.630605-07:00"}
{"id":"bd-17","title":"Add customizable time threshold for compact command","description":"Currently compact uses fixed 30-day and 90-day tiers. Add support for custom time thresholds like '--older-than 60h' or '--older-than 2.5d' to allow more flexible compaction policies.\n\nExamples:\n  bd compact --all --older-than 60h\n  bd compact --all --older-than 2.5d\n  bd compact --all --tier 1 --age 48h\n\nThis would allow users to set their own compaction schedules based on their workflow needs.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.630874-07:00"}
{"id":"bd-18","title":"Implement bd quickstart command","description":"Add bd quickstart command to show context-aware repo information: recent issues, database location, configured prefix, example queries. Helps AI agents understand current project state. Companion to bd onboard.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.631122-07:00"}
{"id":"bd-19","title":"Stress tests pollute production database with test issues","description":"TestStressNoUniqueConstraintViolations and other stress tests in internal/rpc/stress_test.go create issues in production database instead of test database. Confirmed: 1,000 test issues (Agent X Issue Y) created at 20:46:01 during test run. Root cause: test goroutines connect to production daemon at .beads/bd.sock instead of isolated test daemon in temp directory.","acceptance_criteria":"Test with new flag","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.63135-07:00","closed_at":"2025-10-22T09:57:39.762392-07:00"}
{"id":"bd-2","title":"Add merged_into field to database schema","description":"Add merged_into field to Issue struct and update database schema to support merge tracking","notes":"Simplified: no schema field needed. Close merged issues with reason 'Merged into bd-X'. See bd-79 design.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.631612-07:00"}
{"id":"bd-20","title":"Comment test","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T00:37:10.445642-07:00","updated_at":"2025-10-23T13:07:15.631833-07:00","comments":[{"id":5,"issue_id":"bd-20","author":"tester","text":"first comment","created_at":"2025-10-22T07:37:10Z"}]}
{"id":"bd-21","title":"Version test issue","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T00:37:12.263803-07:00","updated_at":"2025-10-23T13:07:15.632047-07:00"}
{"id":"bd-22","title":"Version test issue","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T00:37:12.376494-07:00","updated_at":"2025-10-23T13:07:15.632254-07:00"}
{"id":"bd-23","title":"Version test issue","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T00:37:12.831572-07:00","updated_at":"2025-10-23T13:07:15.634733-07:00"}
{"id":"bd-24","title":"Version test issue","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T00:37:12.946023-07:00","updated_at":"2025-10-23T13:07:15.634976-07:00"}
{"id":"bd-25","title":"Version test issue","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T00:37:13.060099-07:00","updated_at":"2025-10-23T13:07:15.635189-07:00"}
{"id":"bd-26","title":"Version test issue","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T00:37:13.176458-07:00","updated_at":"2025-10-23T13:07:15.635462-07:00"}
{"id":"bd-28","title":"Add cross-repo issue references (future enhancement)","description":"Support referencing issues across different beads repositories. Useful for tracking dependencies between separate projects.\n\nProposed syntax:\n- Local reference: bd-78 (current behavior)\n- Cross-repo by path: ~/src/other-project#bd-456\n- Cross-repo by workspace name: @project2:bd-789\n\nUse cases:\n1. Frontend project depends on backend API issue\n2. Shared library changes blocking multiple projects\n3. System administrator tracking work across machines\n4. Monorepo with separate beads databases per component\n\nImplementation challenges:\n- Storage layer needs to query external databases\n- Dependency resolution across repos\n- What if external repo not available?\n- How to handle in JSONL export/import?\n- Security: should repos be able to read others?\n\nDesign questions to resolve first:\n1. Read-only references vs full cross-repo dependencies?\n2. How to handle repo renames/moves?\n3. Absolute paths vs workspace names vs git remotes?\n4. Should bd-77 auto-discover related repos?\n\nRecommendation: \n- Gather user feedback first\n- Start with read-only references\n- Implement as plugin/extension?\n\nContext: This is mentioned in bd-77 as approach #2. Much more complex than daemon multi-repo approach. Only implement if there's strong user demand.\n\nPriority: Backlog (4) - wait for user feedback before designing","status":"closed","priority":4,"issue_type":"feature","created_at":"2025-10-22T00:54:52.715917-07:00","updated_at":"2025-10-23T13:07:15.635735-07:00","closed_at":"2025-10-20T22:00:31.964329-07:00"}
{"id":"bd-29","title":"Daemon storage cache doesn't detect external database modifications","description":"When bd commands bypass the daemon and directly modify the database (e.g., `bd import` with direct file access, or deleting/recreating bd.db), the daemon's cached storage connection becomes stale and serves outdated data.\n\n**Reproduction**:\n1. Start daemon: `bd daemon`\n2. Run bd stats → shows N issues\n3. Delete database: `rm .beads/bd.db`  \n4. Reinit and import: `bd init \u0026\u0026 bd import -i .beads/issues.jsonl`\n5. Run bd stats → shows 0 issues (wrong!)\n6. Direct query: `sqlite3 .beads/bd.db 'SELECT COUNT(*) FROM issues'` → shows correct count\n7. Restart daemon: `bd daemon --stop` then retry stats → now shows correct count\n\n**Root cause**: \n- server.go:1410-1414 retrieves cached storage without checking if DB file changed\n- Cache only evicts based on TTL (30min) or LRU, never on external modifications\n- Direct file operations bypass daemon, leaving cache stale\n\n**Impact**:\n- Users see incorrect/stale data after external DB operations\n- Confusing behavior with no clear indication cache is stale\n- Requires daemon restart to fix\n\n**Proposed fixes**:\n1. Check mtime on cache hit, invalidate if file changed\n2. Add cache eviction API (bd cache --clear)\n3. Use file locking to prevent external modifications while daemon running\n4. SQLite WAL mode change notifications","design":"**Better approach: Check DB file mtime on cache lookup**\n\nToo many commands bypass the daemon (import, init, renumber, compact, delete, dep tree, export, stale). Notifying from each would be error-prone and easy to forget when adding new commands.\n\n**Implementation:**\n\n1. Add `dbMtime time.Time` field to `StorageCacheEntry`\n2. In `getStorageForRequest()` on cache hit:\n   - Stat the DB file to get current mtime\n   - If mtime changed since cached, evict entry and reopen\n   - Otherwise return cached connection\n3. Store mtime when initially caching\n\n**Code location:**\n- `internal/rpc/server.go:1410-1414` (cache hit path)\n- `internal/rpc/server.go:49-52` (StorageCacheEntry struct)\n\n**Benefits:**\n- Simple, centralized check\n- Works for all commands that bypass daemon\n- Works for external tools modifying DB\n- No need to update every command\n- Minimal performance overhead (one stat() call on cache hit)\n\n**Trade-offs:**\n- Small overhead on every cache hit (negligible - stat is fast)\n- mtime granularity may miss rapid changes (unlikely in practice)","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-22T00:54:52.716221-07:00","updated_at":"2025-10-23T13:07:15.636019-07:00","closed_at":"2025-10-21T21:51:22.331957-07:00"}
{"id":"bd-3","title":"Add CLI merge command and flags","description":"Implement bd merge command with: multiple sources, --into target, --dry-run, --json flags. Add interactive confirmation.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.636317-07:00"}
{"id":"bd-30","title":"Add merged_into field to database schema","description":"Add merged_into field to Issue struct and update database schema to support merge tracking","notes":"Simplified: no schema field needed. Close merged issues with reason 'Merged into bd-X'. See bd-79 design.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.716553-07:00","updated_at":"2025-10-23T13:07:15.636533-07:00"}
{"id":"bd-31","title":"Implement text reference scanning and replacement","description":"Scan all issues for text references to merged IDs (bd-X patterns) and update to target ID. Reuse logic from import collision resolution.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.716781-07:00","updated_at":"2025-10-23T13:07:15.636746-07:00"}
{"id":"bd-32","title":"Add CLI merge command and flags","description":"Implement bd merge command with: multiple sources, --into target, --dry-run, --json flags. Add interactive confirmation.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.716998-07:00","updated_at":"2025-10-23T13:07:15.636942-07:00"}
{"id":"bd-33","title":"Issue counter gets out of sync with actual issues","description":"The issue counter in issue_counters table frequently desyncs from actual max issue ID, causing:\n- Import from JSONL leaves counter at old high value\n- Test pollution increments counter but cleanup doesn't decrement it\n- Delete issues doesn't update counter\n- Only fix is 'rm -rf .beads' which is destructive\n\nExamples from today's session:\n- Had 48 issues but counter at 7714 after test pollution\n- Import from git didn't reset counter\n- Next new issue would be bd-7715 instead of bd-15\n\nProposed fixes:\n1. Auto-recalculate counter from max(issue_id) on import\n2. Add 'bd fix-counter' command\n3. Make counter lazy (always compute from DB, don't store)\n4. Import should reset counter to match imported data\n\nRelated: bd-47 (test isolation), bd-50 (init timestamp bug)","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-22T00:54:52.717233-07:00","updated_at":"2025-10-23T13:07:15.637154-07:00","closed_at":"2025-10-21T23:13:04.249149-07:00"}
{"id":"bd-34","title":"Add transaction support for atomic merges","description":"Wrap all merge operations in SQLite transaction for atomicity. Implement rollback on failure.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.717472-07:00","updated_at":"2025-10-23T13:07:15.637747-07:00"}
{"id":"bd-35","title":"Implement dependency migration for merge","description":"Migrate all dependencies from source issue(s) to target issue during merge, removing duplicates and preserving graph integrity","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.717687-07:00","updated_at":"2025-10-23T13:07:15.638243-07:00"}
{"id":"bd-36","title":"Test issue 2","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.717906-07:00","updated_at":"2025-10-23T13:07:15.638469-07:00","closed_at":"2025-10-21T22:06:41.257019-07:00"}
{"id":"bd-37","title":"Compact command fails with daemon - requires --no-daemon workaround","description":"The 'bd compact' command fails with 'Error: compact requires SQLite storage' when used with the daemon (default mode), but works correctly with the '--no-daemon' flag.\n\nThe daemon RPC interface doesn't properly expose the compact command, even though the daemon itself uses SQLite storage.\n\nReproduction:\n1. Ensure daemon is running (bd daemon status)\n2. Run: bd compact --stats\n   Result: Error: compact requires SQLite storage\n3. Run: bd compact --stats --no-daemon\n   Result: Works correctly, shows statistics\n\nExpected behavior:\nThe compact command should work through the daemon RPC interface just like other commands (list, create, update, delete, renumber, etc.)\n\nImpact:\nUsers cannot use compact operations in the normal workflow. They must use --no-daemon which bypasses the daemon entirely.\n\nSuggested fix:\nAdd compact operation support to the daemon RPC interface, similar to how renumber and other operations are exposed.","status":"in_progress","priority":1,"issue_type":"bug","created_at":"2025-10-22T00:54:52.718118-07:00","updated_at":"2025-10-23T13:07:15.638654-07:00"}
{"id":"bd-38","title":"Add validation/warning for malformed issue IDs","description":"getNextID silently ignores non-numeric ID suffixes (e.g., bd-foo). CAST returns NULL for invalid strings. Consider detecting and warning about malformed IDs in database. Location: internal/storage/sqlite/sqlite.go:79-82","status":"closed","priority":3,"issue_type":"task","created_at":"2025-10-22T00:54:52.718339-07:00","updated_at":"2025-10-23T13:07:15.638933-07:00","closed_at":"2025-10-14T02:51:52.198988-07:00"}
{"id":"bd-39","title":"Investigate stress test database pollution (vc-248)","description":"Investigation of stress tests polluting production database with 1,600+ test issues on Oct 21 at 20:24-20:25. Root cause analysis completed. Tests now verified to work correctly with proper isolation.","notes":"Bug confirmed! Tests DO pollute production DB. 1,000 test issues created at 20:46:01-20:46:02 during TestStressNoUniqueConstraintViolations. Root cause: test goroutines connect to production daemon at .beads/bd.sock instead of test daemon.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.718567-07:00","updated_at":"2025-10-23T13:07:15.639192-07:00"}
{"id":"bd-4","title":"Document merge command and AI integration","description":"Update README, AGENTS.md with merge command examples. Document AI agent duplicate detection workflow.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.639425-07:00"}
{"id":"bd-40","title":"Test issue 1","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.71876-07:00","updated_at":"2025-10-23T13:07:15.639617-07:00","closed_at":"2025-10-21T22:06:41.25599-07:00"}
{"id":"bd-41","title":"Global daemon should warn/reject --auto-commit and --auto-push","description":"When user runs 'bd daemon --global --auto-commit', it's unclear which repo the daemon will commit to (especially after fixing bd-77 where global daemon won't open a DB).\n\nOptions:\n1. Warn and ignore the flags in global mode\n2. Error out with clear message\n\nLine 87-91 already checks autoPush, but should skip check entirely for global mode. Add user-friendly messaging about flag incompatibility.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-10-22T00:54:52.718948-07:00","updated_at":"2025-10-23T13:07:15.639817-07:00","closed_at":"2025-10-17T23:04:30.223432-07:00"}
{"id":"bd-42","title":"bd sync crashes with nil pointer when daemon is running","description":"The 'bd sync' command crashes with a nil pointer dereference when the daemon is running.\n\n**Reproduction:**\n```bash\n# With daemon running\n./bd sync\n```\n\n**Error:**\n```\npanic: runtime error: invalid memory address or nil pointer dereference\n[signal SIGSEGV: segmentation violation code=0x2 addr=0x120 pc=0x1012314ac]\n\ngoroutine 1 [running]:\nmain.exportToJSONL({0x1014ec2e0, 0x101a49900}, {0x14000028db0, 0x30})\n        /Users/stevey/src/fred/beads/cmd/bd/sync.go:245 +0x4c\n```\n\n**Root cause:**\nThe sync command's `exportToJSONL` function directly accesses `store.SearchIssues()` at line 245, but when daemon mode is active, the global `store` variable is nil. The sync command should either:\n1. Use daemon RPC when daemon is running, or\n2. Force direct mode for sync operations\n\n**Workaround:**\nUse `--no-daemon` flag: `bd sync --no-daemon`","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-22T00:54:52.719161-07:00","updated_at":"2025-10-23T13:07:15.640022-07:00","closed_at":"2025-10-22T00:09:12.615536-07:00"}
{"id":"bd-43","title":"Add customizable time threshold for compact command","description":"Currently compact uses fixed 30-day and 90-day tiers. Add support for custom time thresholds like '--older-than 60h' or '--older-than 2.5d' to allow more flexible compaction policies.\n\nExamples:\n  bd compact --all --older-than 60h\n  bd compact --all --older-than 2.5d\n  bd compact --all --tier 1 --age 48h\n\nThis would allow users to set their own compaction schedules based on their workflow needs.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T00:54:52.719355-07:00","updated_at":"2025-10-23T13:07:15.640205-07:00"}
{"id":"bd-44","title":"Add --id flag to bd list for filtering by specific issue IDs","description":"","design":"Add --id flag accepting comma-separated IDs. Usage: bd list --id wy-11,wy-12. Combines with other filters. From filter-flag-design.md.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T00:54:52.719567-07:00","updated_at":"2025-10-23T13:07:15.640415-07:00"}
{"id":"bd-45","title":"Make merge command idempotent for safe retry after partial failures","description":"The merge command currently performs 3 operations without an outer transaction:\n1. Migrate dependencies from source → target\n2. Update text references across all issues\n3. Close source issues\n\nIf merge fails mid-operation (network issue, daemon crash, etc.), a retry will fail or produce incorrect results because some operations already succeeded.\n\n**Goal:** Make merge idempotent so retrying after partial failure is safe and completes the remaining work.\n\n**Idempotency checks needed:**\n- Skip dependency migration if target already has the dependency\n- Skip text reference updates if already updated\n- Skip closing source issues if already closed\n- Report which operations were skipped vs performed\n\n**Example output:**\n```\n✓ Merged 2 issue(s) into bd-78\n  - Dependencies: 3 migrated, 2 already existed\n  - Text references: 5 updated, 0 already correct\n  - Source issues: 1 closed, 1 already closed\n```\n\n**Related:** bd-23 originally requested transaction support, but idempotency is a better solution for this use case since individual operations are already atomic.","design":"Current merge code already has some idempotency:\n- Dependency migration checks `alreadyExists` before adding (line ~145-151 in merge.go)\n- Text reference updates are naturally idempotent (replacing bd-X with bd-Y twice has same result)\n\nMissing idempotency:\n- CloseIssue fails if source already closed\n- Error messages don't distinguish \"already done\" from \"real failure\"\n\nImplementation:\n1. Check source issue status before closing - skip if already closed\n2. Track which operations succeeded/skipped\n3. Return detailed results for user visibility\n4. Consider adding --dry-run output showing what would be done vs skipped","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T00:54:52.719751-07:00","updated_at":"2025-10-23T13:07:15.640605-07:00"}
{"id":"bd-46","title":"Implement bd quickstart command","description":"Add bd quickstart command to show context-aware repo information: recent issues, database location, configured prefix, example queries. Helps AI agents understand current project state. Companion to bd onboard.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T00:54:52.719962-07:00","updated_at":"2025-10-23T13:07:15.640819-07:00"}
{"id":"bd-47","title":"Add godoc comments for auto-flush functions","description":"Add comprehensive godoc comments for findJSONLPath(), markDirtyAndScheduleFlush(), and flushToJSONL() explaining behavior, concurrency considerations, and error handling. Include notes about debouncing behavior (timer resets on each write, flush occurs 5s after LAST operation) and flush-on-exit guarantees. Located in cmd/bd/main.go:188-307.","status":"closed","priority":4,"issue_type":"chore","created_at":"2025-10-22T00:54:52.720152-07:00","updated_at":"2025-10-23T13:07:15.641034-07:00","closed_at":"2025-10-19T19:22:19.172983-07:00"}
{"id":"bd-48","title":"Remove unused issueMap in scoreCollisions","description":"scoreCollisions() creates issueMap and populates it (lines 135-138) but never uses it. Either remove it or add a TODO comment explaining future use. Located in collision.go:135-138. Cosmetic cleanup.","status":"closed","priority":4,"issue_type":"chore","created_at":"2025-10-22T00:54:52.720364-07:00","updated_at":"2025-10-23T13:07:15.641227-07:00","closed_at":"2025-10-19T19:27:34.230312-07:00"}
{"id":"bd-49","title":"Test real auto-export","description":"","status":"closed","priority":4,"issue_type":"task","created_at":"2025-10-22T00:54:52.720584-07:00","updated_at":"2025-10-23T13:07:15.641432-07:00","closed_at":"2025-10-20T22:00:31.967571-07:00"}
{"id":"bd-5","title":"Implement dependency migration for merge","description":"Migrate all dependencies from source issue(s) to target issue during merge, removing duplicates and preserving graph integrity","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.641611-07:00"}
{"id":"bd-50","title":"Consider implementing pre-commit hooks for Storage interface changes","description":"The documentation (INTERFACE_CHANGES.md) suggests adding pre-commit hooks that automatically check for Storage interface changes and verify all mocks are updated. This would prevent similar issues in the future where interface changes break mock implementations.\n\nDiscovered during execution of vc-228 (dogfooding run #14/15).","design":"Implement a pre-commit hook that:\n1. Detects changes to internal/storage/storage.go\n2. Runs scripts/find-storage-mocks.sh to find all mock implementations\n3. Attempts to compile all test files with mocks\n4. Blocks commit if compilation fails\n\nTools: husky, pre-commit framework, or simple .git/hooks/pre-commit script","acceptance_criteria":"- Pre-commit hook installed and documented\n- Hook detects Storage interface changes\n- Hook validates all mocks compile\n- Hook can be bypassed with --no-verify if needed\n- Documentation updated with installation instructions","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T00:54:52.720765-07:00","updated_at":"2025-10-23T13:07:15.641817-07:00"}
{"id":"bd-51","title":"Write tests for merge functionality","description":"Unit tests: validation, merge logic, data integrity. Integration tests: end-to-end workflow, export/import. Edge case tests: chains, circular refs, epics.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T00:54:52.720988-07:00","updated_at":"2025-10-23T13:07:15.642007-07:00"}
{"id":"bd-52","title":"Improve error handling in dependency removal during remapping","description":"In updateDependencyReferences(), RemoveDependency errors are caught and ignored with continue (line 392). Comment says 'if dependency doesn't exist' but this catches ALL errors including real failures. Should check error type with errors.Is(err, ErrDependencyNotFound) and only ignore not-found errors, returning other errors properly.","status":"closed","priority":3,"issue_type":"bug","created_at":"2025-10-22T00:54:52.721182-07:00","updated_at":"2025-10-23T13:07:15.64219-07:00","closed_at":"2025-10-18T09:41:18.209717-07:00"}
{"id":"bd-53","title":"Fix flaky CI tests in compactor and daemon modules","description":"Multiple test failures observed in CI:\n- TestCompactTier1_DryRun  \n- TestCompactTier1Batch_DryRun\n- TestCompactTier1Batch_WithIneligible\n- TestMockAPI_CompactTier1\n- TestBatchOperations_ErrorHandling\n- TestCommentOperationsViaRPC\n- TestMemoryPressureDetection\n- TestPing\n\nAll failures related to 'issue has open dependents or not closed long enough' eligibility checks.\n\nSee CI run: https://github.com/steveyegge/beads/actions/runs/18688772658","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-22T00:54:52.721389-07:00","updated_at":"2025-10-23T13:07:15.642417-07:00"}
{"id":"bd-54","title":"Enforce one daemon per repository","description":"Multiple daemons can run for the same repository, causing race conditions, data corruption, and unpredictable behavior. Need to implement lock file or PID check to ensure only one daemon runs per .beads directory. This has caused production issues including test database pollution (bd-19) and potential concurrent write conflicts.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-22T09:59:04.150972-07:00","updated_at":"2025-10-23T13:07:15.642624-07:00","closed_at":"2025-10-22T10:10:12.583601-07:00"}
{"id":"bd-55","title":"Fix: Import should preserve original timestamps instead of overwriting with current time","description":"Issue GH-121: Import unconditionally overwrites created_at/updated_at in validateBatchIssues(), losing historical dates from external systems (Jira, GitHub). Causes dirty git repo on every import. Fix: Only set timestamps if IsZero().","design":"Change validateBatchIssues() in internal/storage/sqlite/sqlite.go lines 668-669 to check IsZero() before setting timestamps. Preserves existing behavior for new issues while allowing imports to keep original dates.","acceptance_criteria":"Import with historical timestamps preserves them. Import without timestamps still gets current time. No git diff after importing unchanged JSONL.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-23T09:29:27.574435-07:00","updated_at":"2025-10-23T13:07:15.642853-07:00","closed_at":"2025-10-23T09:33:17.315707-07:00"}
{"id":"bd-56","title":"Fix: RemapCollisions deletes existing issue dependencies during import collision resolution","description":"Bug in updateDependencyReferences() was deleting ALL existing issue dependencies during import with --resolve-collisions, not just dependencies from imported issues.\n\nRoot cause: Function was checking if dep.IssueID was in idMapping keys (old imported IDs), but those are also IDs of existing DB issues. Fixed to only update dependencies where IssueID is in idMapping values (new remapped IDs).\n\nDuring normal import, this is now effectively a no-op since imported dependencies haven't been added to DB yet when RemapCollisions runs.\n\nFixes GH issue #120","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-23T10:25:00.691208-07:00","updated_at":"2025-10-23T13:07:15.643069-07:00","closed_at":"2025-10-23T10:25:19.821277-07:00"}
{"id":"bd-57","title":"init command ignores --db flag and BEADS_DB env var","description":"The bd init command hardcodes the database path to .beads/{prefix}.db and ignores both the --db flag and BEADS_DB environment variable. This prevents users from initializing databases outside the project directory.\n\nRoot cause: cmd/bd/init.go line 71 creates a local dbPath variable instead of using the global dbPath from the flag.\n\nRelated to GitHub issue #118.","notes":"Fix completed and reviewed by oracle.\n\nChanges made:\n1. Check BEADS_DB environment variable at start of init command\n2. Use global dbPath if set via --db flag or BEADS_DB, otherwise default to .beads/{prefix}.db\n3. Use proper path comparison (filepath.Abs + filepath.Clean) instead of strings.Contains to determine if database is local\n4. Only create .beads/ directory when database will actually be stored there\n5. Ensure parent directory exists for custom database paths\n6. Added comprehensive tests including edge cases:\n   - Custom path with --db flag\n   - Custom path with BEADS_DB env var\n   - Custom path containing \".beads\" substring (to prevent false positive)\n   - Flag precedence over env var\n\nOracle review feedback implemented:\n- Replaced strings.Contains heuristic with canonical path comparison\n- Added tests for edge cases\n- All init tests passing\n\nThis properly fixes GitHub issue #118.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-23T10:39:34.507356-07:00","updated_at":"2025-10-23T13:07:15.643266-07:00","closed_at":"2025-10-23T10:42:35.761215-07:00"}
{"id":"bd-58","title":"MCP dep tool uses confusing parameter names (from_id/to_id instead of issue_id/depends_on_id)","description":"GitHub issue #113 reports that Claude Code is creating dependencies backwards because the MCP tool parameters are confusing.\n\nCurrent: from_id, to_id (ambiguous - does from_id block to_id or vice versa?)\nShould be: issue_id, depends_on_id (clear - issue_id depends on depends_on_id)\n\nThe CLI uses the clear naming: `bd dep add [issue-id] [depends-on-id]`\nThe MCP tool should match this for consistency and clarity.\n\nFiles to update:\n- integrations/beads-mcp/src/beads_mcp/tools.py (parameter names and docs)\n- integrations/beads-mcp/src/beads_mcp/bd_client.py (if needed)\n- integrations/beads-mcp/src/beads_mcp/bd_daemon_client.py (if needed)\n- All tests that use add_dependency","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-23T11:04:27.792472-07:00","updated_at":"2025-10-23T13:07:15.64348-07:00","closed_at":"2025-10-23T11:09:18.893724-07:00"}
{"id":"bd-6","title":"Fix flaky CI tests in compactor and daemon modules","description":"Multiple test failures observed in CI:\n- TestCompactTier1_DryRun  \n- TestCompactTier1Batch_DryRun\n- TestCompactTier1Batch_WithIneligible\n- TestMockAPI_CompactTier1\n- TestBatchOperations_ErrorHandling\n- TestCommentOperationsViaRPC\n- TestMemoryPressureDetection\n- TestPing\n\nAll failures related to 'issue has open dependents or not closed long enough' eligibility checks.\n\nSee CI run: https://github.com/steveyegge/beads/actions/runs/18688772658","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.643685-07:00"}
{"id":"bd-7","title":"Compact command fails with daemon - requires --no-daemon workaround","description":"The 'bd compact' command fails with 'Error: compact requires SQLite storage' when used with the daemon (default mode), but works correctly with the '--no-daemon' flag.\n\nThe daemon RPC interface doesn't properly expose the compact command, even though the daemon itself uses SQLite storage.\n\nReproduction:\n1. Ensure daemon is running (bd daemon status)\n2. Run: bd compact --stats\n   Result: Error: compact requires SQLite storage\n3. Run: bd compact --stats --no-daemon\n   Result: Works correctly, shows statistics\n\nExpected behavior:\nThe compact command should work through the daemon RPC interface just like other commands (list, create, update, delete, renumber, etc.)\n\nImpact:\nUsers cannot use compact operations in the normal workflow. They must use --no-daemon which bypasses the daemon entirely.\n\nSuggested fix:\nAdd compact operation support to the daemon RPC interface, similar to how renumber and other operations are exposed.","status":"in_progress","priority":1,"issue_type":"bug","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.643872-07:00"}
{"id":"bd-8","title":"Investigate stress test database pollution (vc-248)","description":"Investigation of stress tests polluting production database with 1,600+ test issues on Oct 21 at 20:24-20:25. Root cause analysis completed. Tests now verified to work correctly with proper isolation.","notes":"Bug confirmed! Tests DO pollute production DB. 1,000 test issues created at 20:46:01-20:46:02 during TestStressNoUniqueConstraintViolations. Root cause: test goroutines connect to production daemon at .beads/bd.sock instead of test daemon.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.644082-07:00"}
{"id":"bd-9","title":"Implement text reference scanning and replacement","description":"Scan all issues for text references to merged IDs (bd-X patterns) and update to target ID. Reuse logic from import collision resolution.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T23:00:08.617147-07:00","updated_at":"2025-10-23T13:07:15.644267-07:00"}
